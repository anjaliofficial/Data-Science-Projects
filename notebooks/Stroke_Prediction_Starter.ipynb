{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3519da9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Stroke_Prediction_Starter.ipynb\n",
    "\n",
    "# ==========================\n",
    "# 1️⃣ Import Libraries\n",
    "# ==========================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import shap\n",
    "\n",
    "# ==========================\n",
    "# 2️⃣ Load Dataset\n",
    "# ==========================\n",
    "df = pd.read_csv(\"data/stroke_data.csv\")\n",
    "df.head()\n",
    "\n",
    "# ==========================\n",
    "# 3️⃣ Data Cleaning\n",
    "# ==========================\n",
    "# Drop irrelevant columns\n",
    "df = df.drop(columns=['id'], errors='ignore')\n",
    "\n",
    "# Handle missing BMI values\n",
    "df['bmi'].fillna(df['bmi'].median(), inplace=True)\n",
    "\n",
    "# Encode categorical features\n",
    "label_cols = ['gender','ever_married','work_type','Residence_type','smoking_status']\n",
    "for col in label_cols:\n",
    "    df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "# ==========================\n",
    "# 4️⃣ Exploratory Data Analysis (EDA)\n",
    "# ==========================\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.show()\n",
    "\n",
    "# Stroke distribution by age / hypertension\n",
    "sns.countplot(x='age', hue='stroke', data=df)\n",
    "plt.show()\n",
    "\n",
    "# ==========================\n",
    "# 5️⃣ Handle Class Imbalance\n",
    "# ==========================\n",
    "X = df.drop('stroke', axis=1)\n",
    "y = df['stroke']\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X, y)\n",
    "\n",
    "# ==========================\n",
    "# 6️⃣ Scale Features\n",
    "# ==========================\n",
    "scaler = StandardScaler()\n",
    "X_res_scaled = scaler.fit_transform(X_res)\n",
    "\n",
    "# ==========================\n",
    "# 7️⃣ Train-Test Split\n",
    "# ==========================\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res_scaled, y_res, test_size=0.2, random_state=42)\n",
    "\n",
    "# ==========================\n",
    "# 8️⃣ Train Models\n",
    "# ==========================\n",
    "# Example: XGBoost\n",
    "model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ==========================\n",
    "# 9️⃣ Evaluate Model\n",
    "# ==========================\n",
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nROC AUC Score:\", roc_auc_score(y_test, y_proba))\n",
    "\n",
    "# ==========================\n",
    "# 10️⃣ Feature Importance & SHAP\n",
    "# ==========================\n",
    "explainer = shap.Explainer(model, X_train)\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "shap.summary_plot(shap_values, X_test, feature_names=X.columns)\n",
    "\n",
    "# ==========================\n",
    "# 11️⃣ Save Model & Scaler\n",
    "# ==========================\n",
    "joblib.dump(model, \"models/xgb_model.pkl\")\n",
    "joblib.dump(scaler, \"models/scaler.pkl\")\n",
    "\n",
    "# ==========================\n",
    "# 12️⃣ Optional: Integrate with Streamlit\n",
    "# ==========================\n",
    "# In main_app.py you can load model/scaler and predict on user inputs\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
